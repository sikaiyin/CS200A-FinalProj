{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHW6HjFUovlb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from shutil import copyfile\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Stb0Jphsync"
   },
   "outputs": [],
   "source": [
    "def train_test_split(targetfolder,ratio):\n",
    "    classes = os.listdir(targetfolder)\n",
    "#  Example: train_test_split(\"Plots_v2_clean\",\"Plots_v2_clean_split\",{6:450,7:200,10:650,12:650})\n",
    "    newfolder = targetfolder+'_split'\n",
    "    os.mkdir(newfolder)\n",
    "    for j in [\"train\",\"val\"]:\n",
    "        os.mkdir(newfolder+\"/\"+j)\n",
    "        for i in classes:    \n",
    "            os.mkdir(newfolder+\"/\"+j+\"/\"+str(i))\n",
    "    for i in classes:\n",
    "        path = targetfolder+\"/\"+str(i)+\"/\"\n",
    "        imglist = os.listdir(path)\n",
    "        train_list = random.sample(imglist,int(len(imglist)*ratio))\n",
    "        val_list = list(set(imglist) - set(train_list)) \n",
    "        for j in train_list:\n",
    "            oldpath = path+j\n",
    "            newpath = newfolder+\"/\"+\"train\"+\"/\"+str(i)+\"/\"+j\n",
    "            copyfile(oldpath,newpath)\n",
    "        for j in val_list:\n",
    "            oldpath = path+j\n",
    "            newpath = newfolder+\"/\"+\"val\"+\"/\"+str(i)+\"/\"+j\n",
    "            copyfile(oldpath,newpath)\n",
    "train_test_split('/content/drive/My Drive/DS100 final project/20_categories_training',0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szh7cTF_o9Up"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        \n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/content/drive/My Drive/DS100 final project/20_categories_training_split'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdskC8kjaUeK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Q9Jfm2cVYmOx",
    "outputId": "4c3109b0-a2dd-4b8e-8161-69d1688f809e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aw4UOJyVlYbv"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 224, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(224, 224, kernel_size=3, padding=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(224 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 20),\n",
    "        )\n",
    "#https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "net = Net()\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwCZF39mCgBs"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validation_accuracy():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['val']:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "    return correct / total\n",
    "            \n",
    "\n",
    "def train(net,epoch):\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    best_acc = 0.59\n",
    "    for epoch in range(epoch):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloaders['train'], 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            l1_regularization = 0\n",
    "            lambda_ = 0.00001\n",
    "            for param in net.parameters():\n",
    "                l1_regularization += torch.norm(param, 1)\n",
    "            loss = loss + lambda_*l1_regularization \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print('[%d] loss: %.3f' %\n",
    "                (epoch + 1, running_loss / len(dataloaders['train'])))\n",
    "        val_acc = validation_accuracy()\n",
    "        if val_acc>best_acc:\n",
    "            path = '/content/drive/My Drive/DS100 final project/CNN.pth'\n",
    "            best_acc = val_acc\n",
    "            torch.save(net.state_dict(), PATH)\n",
    "            print('saved model')\n",
    "        running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "J4SP6RP1DQ1t",
    "outputId": "e020c36d-26d2-408a-d24d-a9db0dd4826d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 4.339\n",
      "Accuracy of the network on the test images: 57 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJsFKENSz3TU"
   },
   "outputs": [],
   "source": [
    "PATH = '/content/drive/My Drive/DS100 final project/CNN.pth'\n",
    "torch.save(best_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8eGYv4-DaUl_",
    "outputId": "a7c2e7e0-a09f-4efb-b58b-28c04ddddc4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/content/drive/My Drive/DS100 final project/CNN.pth'\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rlw0ws360Ije"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DS100.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
